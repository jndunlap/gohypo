package validation

import (
	"context"
	"fmt"
	"log"
	"strings"

	"gohypo/internal/analysis/brief"
	"gohypo/models"
)

// HeuristicAuditor provides fallback validation logic when LLM auditor fails
type HeuristicAuditor struct {
	statisticalEngine *brief.StatisticalEngine
}

// NewHeuristicAuditor creates a new heuristic auditor
func NewHeuristicAuditor(statisticalEngine *brief.StatisticalEngine) *HeuristicAuditor {
	return &HeuristicAuditor{
		statisticalEngine: statisticalEngine,
	}
}

// GetHeuristicDirective generates referee selection based on statistical heuristics
func (ha *HeuristicAuditor) GetHeuristicDirective(
	ctx context.Context,
	hypothesis *models.ResearchDirectiveResponse,
	xData, yData []float64,
) (*AuditorDirective, error) {

	log.Printf("[HeuristicAuditor] Generating fallback directive for hypothesis: %s", hypothesis.ID)

	// Analyze the hypothesis text for semantic clues
	hypothesisType := ha.classifyHypothesisType(hypothesis)

	// Analyze data characteristics
	dataProfile := ha.analyzeDataProfile(xData, yData)

	// Generate referee recommendations based on heuristics
	selectedReferees := ha.generateHeuristicReferees(hypothesisType, dataProfile)

	// Create directive
	directive := &AuditorDirective{
		Decision:        "APPROVE", // Heuristic auditor always approves (fails safe)
		ConfidenceScore: 0.7,       // Moderate confidence for heuristic decisions
		HypothesisAnalysis: HypothesisAnalysis{
			Type:               hypothesisType,
			DirectionalClaims:  ha.detectDirectionalClaims(hypothesis),
			TemporalElements:   ha.detectTemporalElements(hypothesis),
			ComplexityLevel:    ha.assessComplexity(dataProfile),
			KeyTerms:          ha.extractKeyTerms(hypothesis),
			BusinessStake:      "TACTICAL", // Default for heuristic decisions
		},
		DataAssessment: DataAssessment{
			SampleSize:        len(xData),
			DistributionType:  dataProfile.DistributionType,
			DataStructure:     dataProfile.DataStructure,
			QualityFlags:      dataProfile.QualityFlags,
			AssumptionConcerns: dataProfile.AssumptionConcerns,
		},
		RefereeDirective: RefereeDirective{
			SelectedReferees:   selectedReferees,
			EnsembleStrategy:   ha.generateEnsembleStrategy(hypothesisType, dataProfile),
			ExecutionPriority:  "SEQUENTIAL", // Conservative for heuristics
			ExpectedDuration:   ha.estimateDuration(selectedReferees),
			ComputationalBudget: ha.calculateBudget(selectedReferees),
			ConfidenceThreshold: 0.8,
		},
		Severity:         "LOW",
		RecommendedAction: "PROCEED_TO_VALIDATION",
		ProcessingNotes:  "Generated by heuristic auditor fallback - consider LLM validation when available",
	}

	return directive, nil
}

// classifyHypothesisType determines the type of hypothesis from text analysis
func (ha *HeuristicAuditor) classifyHypothesisType(hypothesis *models.ResearchDirectiveResponse) string {
	businessText := strings.ToLower(hypothesis.BusinessHypothesis)
	scienceText := strings.ToLower(hypothesis.ScienceHypothesis)

	// Check for causal indicators
	if strings.Contains(businessText, "cause") || strings.Contains(businessText, "lead") ||
	   strings.Contains(businessText, "drive") || strings.Contains(businessText, "impact") ||
	   strings.Contains(scienceText, "causal") || strings.Contains(scienceText, "influence") {
		return "CAUSAL"
	}

	// Check for temporal indicators
	if strings.Contains(businessText, "lag") || strings.Contains(businessText, "delay") ||
	   strings.Contains(businessText, "follow") || strings.Contains(businessText, "after") ||
	   strings.Contains(businessText, "before") || strings.Contains(scienceText, "temporal") {
		return "TEMPORAL"
	}

	// Check for mechanistic indicators
	if strings.Contains(businessText, "how") || strings.Contains(businessText, "mechanism") ||
	   strings.Contains(businessText, "through") || strings.Contains(businessText, "via") ||
	   strings.Contains(scienceText, "functional") || strings.Contains(scienceText, "relationship") {
		return "MECHANISTIC"
	}

	// Default to associative
	return "ASSOCIATIVE"
}

// analyzeDataProfile examines the statistical properties of the data
func (ha *HeuristicAuditor) analyzeDataProfile(xData, yData []float64) *DataProfile {
	profile := &DataProfile{
		SampleSize: len(xData),
	}

	// Determine data structure
	if ha.detectTimeSeries(xData) {
		profile.DataStructure = "TIME_SERIES"
	} else {
		profile.DataStructure = "CROSS_SECTIONAL"
	}

	// Analyze distribution (simplified)
	if ha.isNormalDistribution(xData) && ha.isNormalDistribution(yData) {
		profile.DistributionType = "NORMAL"
	} else if ha.hasOutliers(xData) || ha.hasOutliers(yData) {
		profile.DistributionType = "HEAVY_TAILED"
	} else {
		profile.DistributionType = "SKEWED"
	}

	// Quality assessment
	if len(xData) < 50 {
		profile.QualityFlags = append(profile.QualityFlags, "SMALL_SAMPLE")
	}
	if ha.hasOutliers(xData) || ha.hasOutliers(yData) {
		profile.QualityFlags = append(profile.QualityFlags, "OUTLIERS")
	}

	// Assumption concerns
	if profile.DistributionType != "NORMAL" {
		profile.AssumptionConcerns = append(profile.AssumptionConcerns, "non-normality")
	}
	if profile.SampleSize < 30 {
		profile.AssumptionConcerns = append(profile.AssumptionConcerns, "small_sample")
	}

	return profile
}

// generateHeuristicReferees selects referees based on heuristic rules
func (ha *HeuristicAuditor) generateHeuristicReferees(hypothesisType string, dataProfile *DataProfile) []SelectedReferee {
	var referees []SelectedReferee

	// Always include Permutation Shredder for any statistical skepticism
	referees = append(referees, SelectedReferee{
		Name:              "Permutation_Shredder",
		Category:          "SHREDDER",
		Priority:          1, // Mandatory
		Rationale:        "Always include non-parametric integrity test",
		ComputationalCost: 2,
		StatisticalPower:  "Guards against spurious correlations regardless of data distribution",
		AssumptionChecks:  []string{"no_distribution_assumptions"},
		FailureImplications: "Cannot trust any parametric test results",
	})

	// Type-specific referees
	switch hypothesisType {
	case "CAUSAL":
		referees = append(referees, SelectedReferee{
			Name:              "Transfer_Entropy",
			Category:          "DIRECTIONAL",
			Priority:          1, // Mandatory for causal claims
			Rationale:        "Hypothesis claims causality - directional test required",
			ComputationalCost: 6,
			StatisticalPower:  "Detects information flow direction in causal relationships",
			AssumptionChecks:  []string{"stationarity"},
		})

	case "TEMPORAL":
		referees = append(referees, SelectedReferee{
			Name:              "Wavelet_Coherence",
			Category:          "SPECTRAL",
			Priority:          2,
			Rationale:        "Temporal hypothesis - frequency domain analysis needed",
			ComputationalCost: 6,
			StatisticalPower:  "Analyzes relationships across different time frequencies",
		})

	case "MECHANISTIC":
		referees = append(referees, SelectedReferee{
			Name:              "Isotonic_Mechanism_Check",
			Category:          "MECHANISM",
			Priority:          2,
			Rationale:        "Mechanistic hypothesis - functional form validation required",
			ComputationalCost: 4,
			StatisticalPower:  "Validates monotonic relationships and functional forms",
		})
	}

	// Data-quality based referees
	if dataProfile.SampleSize < 100 {
		referees = append(referees, SelectedReferee{
			Name:              "LOO_Cross_Validation",
			Category:          "SENSITIVITY",
			Priority:          2,
			Rationale:        "Small sample size - robustness validation needed",
			ComputationalCost: 2,
			StatisticalPower:  "Tests prediction stability with limited data",
		})
	}

	if dataProfile.DistributionType != "NORMAL" {
		// Ensure we have non-parametric options
		hasNonParametric := false
		for _, ref := range referees {
			if ref.Name == "Permutation_Shredder" || ref.Name == "Conditional_MI" {
				hasNonParametric = true
				break
			}
		}
		if !hasNonParametric {
			referees = append(referees, SelectedReferee{
				Name:              "Conditional_MI",
				Category:          "ANTI_CONFOUNDER",
				Priority:          2,
				Rationale:        "Non-normal data - non-parametric causal analysis needed",
				ComputationalCost: 4,
				StatisticalPower:  "Tests direct relationships controlling for confounders",
			})
		}
	}

	return referees
}

// Helper methods for data analysis
func (ha *HeuristicAuditor) detectDirectionalClaims(hypothesis *models.ResearchDirectiveResponse) bool {
	text := strings.ToLower(hypothesis.BusinessHypothesis + " " + hypothesis.ScienceHypothesis)
	return strings.Contains(text, "cause") || strings.Contains(text, "lead") ||
		   strings.Contains(text, "drive") || strings.Contains(text, "impact")
}

func (ha *HeuristicAuditor) detectTemporalElements(hypothesis *models.ResearchDirectiveResponse) bool {
	text := strings.ToLower(hypothesis.BusinessHypothesis + " " + hypothesis.ScienceHypothesis)
	return strings.Contains(text, "lag") || strings.Contains(text, "delay") ||
		   strings.Contains(text, "follow") || strings.Contains(text, "after") ||
		   strings.Contains(text, "before") || strings.Contains(text, "temporal")
}

func (ha *HeuristicAuditor) assessComplexity(dataProfile *DataProfile) string {
	if dataProfile.SampleSize > 1000 && dataProfile.DataStructure == "TIME_SERIES" {
		return "COMPLEX"
	} else if dataProfile.SampleSize > 100 {
		return "MODERATE"
	}
	return "SIMPLE"
}

func (ha *HeuristicAuditor) extractKeyTerms(hypothesis *models.ResearchDirectiveResponse) []string {
	var terms []string
	text := strings.ToLower(hypothesis.BusinessHypothesis + " " + hypothesis.ScienceHypothesis)

	keywords := []string{"cause", "lead", "drive", "impact", "lag", "correlation", "relationship"}
	for _, keyword := range keywords {
		if strings.Contains(text, keyword) {
			terms = append(terms, keyword)
		}
	}

	return terms
}

func (ha *HeuristicAuditor) detectTimeSeries(data []float64) bool {
	// Simple heuristic: look for sequential patterns
	// In real implementation, this would use more sophisticated time series detection
	return len(data) > 10 // Placeholder
}

func (ha *HeuristicAuditor) isNormalDistribution(data []float64) bool {
	// Simplified normality test - in real implementation use statistical tests
	if len(data) < 3 {
		return false
	}
	// Placeholder - would use Shapiro-Wilk or other normality tests
	return true // Assume normal for heuristic purposes
}

func (ha *HeuristicAuditor) hasOutliers(data []float64) bool {
	// Simple outlier detection using IQR method
	if len(data) < 4 {
		return false
	}
	// Placeholder - would implement proper outlier detection
	return false
}

func (ha *HeuristicAuditor) generateEnsembleStrategy(hypothesisType string, dataProfile *DataProfile) string {
	switch hypothesisType {
	case "CAUSAL":
		return "Causal validation requires directional + integrity testing"
	case "TEMPORAL":
		return "Temporal analysis needs frequency + directional methods"
	case "MECHANISTIC":
		return "Mechanistic validation focuses on functional form + robustness"
	default:
		return "Standard correlation analysis with integrity checks"
	}
}

func (ha *HeuristicAuditor) estimateDuration(referees []SelectedReferee) string {
	totalCost := 0
	for _, ref := range referees {
		totalCost += ref.ComputationalCost
	}

	// Rough estimation: 1 cost unit = 2 seconds
	estimatedSeconds := totalCost * 2

	if estimatedSeconds < 60 {
		return fmt.Sprintf("%d seconds", estimatedSeconds)
	}
	return fmt.Sprintf("%.1f minutes", float64(estimatedSeconds)/60.0)
}

func (ha *HeuristicAuditor) calculateBudget(referees []SelectedReferee) int {
	totalCost := 0
	for _, ref := range referees {
		totalCost += ref.ComputationalCost
	}
	return totalCost + 2 // Add buffer
}

// DataProfile represents statistical properties of the data
type DataProfile struct {
	SampleSize        int      `json:"sample_size"`
	DistributionType  string   `json:"distribution_type"`
	DataStructure     string   `json:"data_structure"`
	QualityFlags      []string `json:"quality_flags"`
	AssumptionConcerns []string `json:"assumption_concerns"`
}
